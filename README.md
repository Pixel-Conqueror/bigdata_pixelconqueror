# üé¨ Syst√®me de Recommandation de Films

## üåç Vue d'ensemble

Ce projet impl√©mente un syst√®me de recommandation de films utilisant une architecture Big Data avec :

- **Hadoop HDFS** pour le stockage distribu√©
- **Spark** pour le traitement des donn√©es
- **Kafka** pour le streaming en temps r√©el
- **MongoDB** pour le stockage des donn√©es nettoy√©es
- **ALS (Alternating Least Squares)** pour l'algorithme de recommandation

## üöÄ D√©marrage rapide

### Pr√©requis

- Docker et Docker Compose
- Python 3.x

### Installation

Vous avez le choix entre deux approches :

#### 1. Approche automatis√©e (recommand√©e)

```bash
# Pipeline compl√®te
make pipeline

# ou version all√©g√©e
make pipeline_light
```

#### 2. Approche manuelle (√©tape par √©tape)

1. **Lancer l'environnement Docker**

```bash
make up
```

2. **Initialiser HDFS et ing√©rer les donn√©es**

```bash
make init_hdfs
```

3. **Nettoyer et enrichir les donn√©es (ETL)**

```bash
make batch_etl
# ou version all√©g√©e
make batch_etl_light
```

4. **Charger les donn√©es dans MongoDB**

```bash
make load_to_mongo
```

5. **Entra√Æner le mod√®le ALS**

```bash
make train_als
```

6. **G√©n√©rer les recommandations**

```bash
make generate_recs
```

7. **Lancer le streaming**

```bash
make streaming
```

````

## üõ†Ô∏è Commandes utiles

### Gestion de l'environnement

```bash
# Arr√™ter l'environnement
make down

# Voir les logs
make logs
````

### Backend

```bash
# Acc√©der au shell du backend
make backend-shell

# Voir les logs du backend
make backend-logs
```

### MongoDB

```bash
# Acc√©der au shell MongoDB
make mongo-shell
```

### Kafka

```bash
# Lister les topics Kafka
make kafka-topics
```

### Jupyter

```bash
# Obtenir le token Jupyter
make jupyter-token
```

## üìä Architecture

- **Frontend** : http://localhost:3000
- **Backend API** : http://localhost:5001
- **MongoDB** : localhost:27017
- **Hadoop HDFS Namenode UI** : http://localhost:9870
- **Spark Master UI** : http://localhost:8080
- **Kafka** : localhost:9092
- **Jupyter Notebook** : http://localhost:8888

## üìÅ Structure du projet

```
/
|-- Dockerfile
|-- docker-compose.yml
|-- Makefile
|-- requirements.txt
|-- config/
|   |-- hadoop/
|-- scripts/
    |-- etl_batch.py
    |-- etl_batch_light.py
    |-- generate_all_recommendations.py
    |-- ingest_to_mongo.py
    |-- init_hdfs.sh
    |-- streaming_recommendations.py
    |-- test_update_user.py
    |-- train_als.py
```

## üîî Notes importantes

- Assurez-vous d'avoir suffisamment de m√©moire disponible pour Spark (4GB minimum)
- Les donn√©es doivent √™tre correctement format√©es avant l'ingestion
- Le mod√®le ALS n√©cessite des donn√©es nettoy√©es pour un bon entra√Ænement

---

Made with ‚ù§Ô∏è by Robin, Thomas et Sonny
