{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66df0b2",
   "metadata": {},
   "source": [
    "# Entraînement et Évaluation du Modèle ALS\n",
    "\n",
    "Ce notebook couvre :\n",
    "1. Lecture des données nettoyées  \n",
    "2. Construction du jeu train/test  \n",
    "3. Recherche des hyperparamètres (RMSE, MAE)  \n",
    "4. Évaluation des métriques de ranking (Precision@10, Recall@10, MAP, NDCG)  \n",
    "5. Sauvegarde du meilleur modèle dans HDFS  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec38079",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark.sql.functions import expr, collect_list\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS_Training\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3747f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# On lit les données CSV issues de l’ETL batch\n",
    "ratings = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/movielens/processed/batch/ratings_csv\",\n",
    "    header=True, inferSchema=True\n",
    ").select(\"userId\",\"movieId\",\"rating\")\n",
    "\n",
    "print(f\"Total interactions : {ratings.count()}\")\n",
    "ratings.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfe2a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([0.8,0.2], seed=42)\n",
    "print(f\"▷ Train: {train.count()} lignes  •  Test: {test.count()} lignes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88833f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ranks  = [10,20,30]\n",
    "regs   = [0.01,0.1]\n",
    "iters  = [5,10]\n",
    "best_rmse = float(\"inf\")\n",
    "best_model = None\n",
    "results=[]\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                     labelCol=\"rating\",\n",
    "                                     predictionCol=\"prediction\")\n",
    "evaluator_mae  = RegressionEvaluator(metricName=\"mae\",\n",
    "                                     labelCol=\"rating\",\n",
    "                                     predictionCol=\"prediction\")\n",
    "\n",
    "for rank in ranks:\n",
    "    for reg in regs:\n",
    "        for n in iters:\n",
    "            als = ALS(userCol=\"userId\",\n",
    "                      itemCol=\"movieId\",\n",
    "                      ratingCol=\"rating\",\n",
    "                      coldStartStrategy=\"drop\",\n",
    "                      rank=rank,\n",
    "                      regParam=reg,\n",
    "                      maxIter=n)\n",
    "            model = als.fit(train)\n",
    "            preds = model.transform(test)\n",
    "            rmse = evaluator_rmse.evaluate(preds)\n",
    "            mae  = evaluator_mae.evaluate(preds)\n",
    "            results.append((rank,reg,n,rmse,mae))\n",
    "            print(f\"rank={rank}  reg={reg}  iter={n}  →  RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse, best_model = rmse, model\n",
    "\n",
    "import pandas as pd\n",
    "df_res = pd.DataFrame(results, columns=[\"rank\",\"regParam\",\"iter\",\"rmse\",\"mae\"])\n",
    "df_res.sort_values(\"rmse\").head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47969c67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Générer top-10 pour chaque user\n",
    "recs = best_model.recommendForAllUsers(10) \\\n",
    "    .select(\"userId\",\n",
    "            expr(\"transform(recommendations, x -> x.movieId) as pred\"))\n",
    "\n",
    "# Construire la vérité terrain à partir du test\n",
    "actual = test.groupBy(\"userId\") \\\n",
    "    .agg(collect_list(\"movieId\").alias(\"actual\"))\n",
    "\n",
    "# Préparer RDD (predictions, labels)\n",
    "pred_and_labels = recs.join(actual, \"userId\") \\\n",
    "    .select(\"pred\",\"actual\") \\\n",
    "    .rdd.map(lambda r: (r.pred, r.actual))\n",
    "\n",
    "metrics = RankingMetrics(pred_and_labels)\n",
    "print(f\"Precision@10 : {metrics.precisionAt(10):.4f}\")\n",
    "print(f\"Recall@10    : {metrics.recallAt(10):.4f}\")\n",
    "print(f\"MAP@10       : {metrics.meanAveragePrecision:.4f}\")\n",
    "print(f\"NDCG@10      : {metrics.ndcgAt(10):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9cc00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_model.write().overwrite().save(\n",
    "    \"hdfs://namenode:9000/movielens/models/als_best\"\n",
    ")\n",
    "print(\"✅ Modèle sauvegardé dans HDFS : /movielens/models/als_best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db6edb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
