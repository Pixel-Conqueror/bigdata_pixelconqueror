{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66df0b2",
   "metadata": {},
   "source": [
    "# Notebook : Entraînement ALS optimisé\n",
    "\n",
    "Ce notebook illustre un pipeline d’entraînement ALS sous Spark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec38079",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "# Démarrage de Spark avec des ressources adaptées\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ALS_Training_Optimized\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")\n",
    "    .config(\"spark.executor.memory\", \"6g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e859b3",
   "metadata": {},
   "source": [
    "## 2. Chargement et mise en cache des données\n",
    "\n",
    "On lit le fichier CSV depuis HDFS, on sélectionne les colonnes utiles et on conserve en cache.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3747f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Lecture des évaluations et mise en cache pour éviter de relire à chaque opération\n",
    "ratings = (\n",
    "    spark.read\n",
    "    .csv(\"hdfs://namenode:9000/movielens/processed/batch/ratings_csv\",\n",
    "         header=True, inferSchema=True)\n",
    "    .select(\"userId\", \"movieId\", \"rating\")\n",
    "    .persist(StorageLevel.MEMORY_AND_DISK)\n",
    ")\n",
    "\n",
    "# Déclenche le calcul et affiche le nombre total d’interactions\n",
    "total = ratings.count()\n",
    "print(f\"▷ Total interactions : {total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426cc79",
   "metadata": {},
   "source": [
    "## 3. Séparation train / test\n",
    "\n",
    "On garde 80 % des données pour l’entraînement et 20 % pour la validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfe2a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "train = train.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "test = test.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "print(f\"▷ Entraînement : {train.count()}  •  Test : {test.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f2f16e",
   "metadata": {},
   "source": [
    "## 4. Définition du modèle et grille d’hyperparamètres\n",
    "\n",
    "On utilise ALS avec `coldStartStrategy=\"drop\"` et on prépare une grille pour la recherche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88833f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Modèle de base\n",
    "als = ALS(\n",
    "    userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Évaluateur RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Grille de paramètres\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(als.rank, [10, 20, 30])\n",
    "    .addGrid(als.regParam, [0.01, 0.1])\n",
    "    .addGrid(als.maxIter, [5, 10])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Recherche systématique avec validation croisée simplifiée\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4  # Ajuster selon le nombre de cœurs dispo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39df729",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 5. Entraînement et choix du meilleur modèle\n",
    "\n",
    "La méthode `fit` parcourt automatiquement tous les réglages de la grille.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47969c67",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Lancement de l’entraînement\n",
    "tvsModel = tvs.fit(train)\n",
    "bestModel = tvsModel.bestModel\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "best_rank = bestModel._java_obj.parent().getOrDefault(als.rank)\n",
    "best_reg = bestModel._java_obj.parent().getOrDefault(als.regParam)\n",
    "best_iter = bestModel._java_obj.parent().getOrDefault(als.maxIter)\n",
    "print(f\"▷ Meilleurs paramètres : rank={best_rank}, regParam={best_reg}, maxIter={best_iter}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9863f5",
   "metadata": {},
   "source": [
    "## 6. Évaluation sur l’ensemble de test\n",
    "\n",
    "On calcule le RMSE et le MAE pour vérifier la qualité des prédictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9cc00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Prédictions et évaluation\n",
    "predictions = bestModel.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "mae = RegressionEvaluator(\n",
    "    metricName=\"mae\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ").evaluate(predictions)\n",
    "\n",
    "print(f\"▷ Test RMSE : {rmse:.4f}\")\n",
    "print(f\"▷ Test MAE : {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db6edb",
   "metadata": {},
   "source": [
    "## 7. Calcul des métriques de ranking\n",
    "\n",
    "On génère les recommandations pour tous les utilisateurs et on compare avec le test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1b5ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, collect_list\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "# Générer les 10 meilleures suggestions par utilisateur\n",
    "recs = (\n",
    "    bestModel\n",
    "    .recommendForAllUsers(10)\n",
    "    .select(\"userId\", expr(\"transform(recommendations, x -> x.movieId) as pred\"))\n",
    ")\n",
    "\n",
    "# Rassembler les films réellement vus\n",
    "actual = (\n",
    "    test\n",
    "    .groupBy(\"userId\")\n",
    "    .agg(collect_list(\"movieId\").alias(\"actual\"))\n",
    ")\n",
    "\n",
    "# Préparer pour RankingMetrics\n",
    "pred_and_labels = (\n",
    "    recs.join(actual, \"userId\")\n",
    "    .select(\"pred\", \"actual\")\n",
    "    .rdd.map(lambda r: (r.pred, r.actual))\n",
    ")\n",
    "\n",
    "metrics = RankingMetrics(pred_and_labels)\n",
    "print(f\"Precision@10 : {metrics.precisionAt(10):.4f}\")\n",
    "print(f\"Recall@10    : {metrics.recallAt(10):.4f}\")\n",
    "print(f\"MAP@10       : {metrics.meanAveragePrecision:.4f}\")\n",
    "print(f\"NDCG@10      : {metrics.ndcgAt(10):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdccf5",
   "metadata": {},
   "source": [
    "## 8. Sauvegarde du modèle\n",
    "\n",
    "On écrase l’ancien modèle et on stocke le nouveau dans HDFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62a8f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bestModel.write().overwrite().save(\n",
    "    \"hdfs://namenode:9000/movielens/models/als_best\"\n",
    ")\n",
    "print(\"✅ Modèle sauvegardé dans HDFS sous /movielens/models/als_best\")\n",
    "\n",
    "# Arrêt de la session Spark\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
